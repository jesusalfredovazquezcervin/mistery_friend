{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8869af05",
   "metadata": {},
   "source": [
    "# Mystery Friend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e05f6",
   "metadata": {},
   "source": [
    "You've received an anonymous postcard from a friend who you haven't seen in years. Your friend did not leave a name, but the card is definitely addressed to you. So far, you've narrowed your search down to three friends, based on handwriting:\n",
    "- Emma Goldman\n",
    "- Matthew Henson\n",
    "- TingFang Wu\n",
    "\n",
    "But which one sent you the card?\n",
    "\n",
    "Just like you can classify a message as spam or not spam with a spam filter, you can classify writing as related to one friend or another by building a kind of friend writing classifier. You have past writing from all three friends stored up in the variable `friends_docs`, which means you can use scikit-learn's bag-of-words and Naive Bayes classifier to determine who the mystery friend is!\n",
    "\n",
    "Ready?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1d856",
   "metadata": {},
   "source": [
    "## Feature Vectors Are in the Bag with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9ff3",
   "metadata": {},
   "source": [
    "1. In the code block below, import `CountVectorizer` from `sklearn.feature_extraction.text`. Below it, import `MultinomialNB` from `sklearn.naive_bayes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccbd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn modules here:\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Import CountVectorizer from sklearn:\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a2a00",
   "metadata": {},
   "source": [
    "2. Define `bow_vectorizer` as an implementation of `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d6464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow_vectorizer:\n",
    "bow_vectorizer=CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a39cb",
   "metadata": {},
   "source": [
    "3. Use your newly minted `bow_vectorizer` to both `fit` (train) and `transform` (vectorize) all your friends' writing (stored in the variable `friends_docs`). Save the resulting vector object as `friends_vectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1366163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friend_vectors ->   (0, 3004)\t5\n",
      "  (0, 1469)\t2\n",
      "  (0, 2103)\t4\n",
      "  (0, 1500)\t1\n",
      "  (0, 1385)\t1\n",
      "  (0, 204)\t1\n",
      "  (0, 862)\t1\n",
      "  (0, 1653)\t1\n",
      "  (0, 285)\t1\n",
      "  (0, 2619)\t1\n",
      "  (0, 3048)\t1\n",
      "  (0, 2996)\t1\n",
      "  (0, 2898)\t1\n",
      "  (0, 1095)\t1\n",
      "  (0, 2046)\t1\n",
      "  (0, 1516)\t1\n",
      "  (0, 1453)\t1\n",
      "  (0, 234)\t1\n",
      "  (0, 441)\t1\n",
      "  (0, 783)\t1\n",
      "  (1, 3004)\t5\n",
      "  (1, 2103)\t2\n",
      "  (1, 204)\t1\n",
      "  (1, 2046)\t1\n",
      "  (1, 1542)\t2\n",
      "  :\t:\n",
      "  (460, 2406)\t1\n",
      "  (460, 546)\t1\n",
      "  (460, 641)\t1\n",
      "  (460, 2746)\t1\n",
      "  (460, 1673)\t1\n",
      "  (460, 3157)\t1\n",
      "  (460, 1912)\t1\n",
      "  (460, 662)\t1\n",
      "  (460, 230)\t1\n",
      "  (460, 614)\t2\n",
      "  (460, 2514)\t1\n",
      "  (460, 1859)\t1\n",
      "  (460, 3094)\t1\n",
      "  (460, 2056)\t1\n",
      "  (460, 341)\t1\n",
      "  (460, 904)\t1\n",
      "  (460, 1193)\t1\n",
      "  (460, 485)\t1\n",
      "  (460, 1110)\t1\n",
      "  (460, 3209)\t1\n",
      "  (460, 616)\t1\n",
      "  (460, 257)\t1\n",
      "  (460, 561)\t1\n",
      "  (460, 2697)\t1\n",
      "  (460, 2623)\t1\n",
      "Test vectors ->   (0, 204)\t1\n",
      "  (0, 234)\t1\n",
      "  (0, 285)\t1\n",
      "  (0, 441)\t1\n",
      "  (0, 783)\t1\n",
      "  (0, 862)\t1\n",
      "  (0, 1095)\t1\n",
      "  (0, 1385)\t1\n",
      "  (0, 1453)\t1\n",
      "  (0, 1469)\t2\n",
      "  (0, 1500)\t1\n",
      "  (0, 1516)\t1\n",
      "  (0, 1653)\t1\n",
      "  (0, 2046)\t1\n",
      "  (0, 2103)\t4\n",
      "  (0, 2619)\t1\n",
      "  (0, 2898)\t1\n",
      "  (0, 2996)\t1\n",
      "  (0, 3004)\t5\n",
      "  (0, 3048)\t1\n",
      "  (1, 138)\t1\n",
      "  (1, 204)\t1\n",
      "  (1, 274)\t1\n",
      "  (1, 756)\t1\n",
      "  (1, 1250)\t1\n",
      "  :\t:\n",
      "  (460, 1905)\t1\n",
      "  (460, 1912)\t1\n",
      "  (460, 2056)\t1\n",
      "  (460, 2103)\t2\n",
      "  (460, 2116)\t1\n",
      "  (460, 2406)\t1\n",
      "  (460, 2411)\t1\n",
      "  (460, 2514)\t1\n",
      "  (460, 2541)\t1\n",
      "  (460, 2623)\t1\n",
      "  (460, 2635)\t1\n",
      "  (460, 2697)\t1\n",
      "  (460, 2746)\t1\n",
      "  (460, 2855)\t2\n",
      "  (460, 3003)\t1\n",
      "  (460, 3004)\t8\n",
      "  (460, 3052)\t3\n",
      "  (460, 3094)\t1\n",
      "  (460, 3157)\t1\n",
      "  (460, 3159)\t2\n",
      "  (460, 3209)\t1\n",
      "  (460, 3288)\t1\n",
      "  (460, 3296)\t1\n",
      "  (460, 3323)\t1\n",
      "  (460, 3349)\t3\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "\n",
    "from goldman_emma_raw import goldman_docs\n",
    "from henson_matthew_raw import henson_docs\n",
    "from wu_tingfang_raw import wu_docs\n",
    "\n",
    "friends_docs = goldman_docs + henson_docs + wu_docs\n",
    "\n",
    "# Define friends_vectors:\n",
    "friends_vectors = bow_vectorizer.fit_transform(friends_docs)\n",
    "print(\"Friend_vectors ->\", friends_vectors)\n",
    "test_vectors = bow_vectorizer.transform(friends_docs)\n",
    "print(\"Test vectors ->\", test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21578a5d",
   "metadata": {},
   "source": [
    "4. Create a new variable `mystery_vector`. Assign to it the vectorized form of `[mystery_postcard]` using the vectorizer's `.transform()` method.\n",
    "\n",
    "   (`mystery_postcard` is a string, while the vectorizer expects a list as an argument.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d7dc322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistery vector ->   (0, 144)\t1\n",
      "  (0, 171)\t1\n",
      "  (0, 204)\t1\n",
      "  (0, 218)\t2\n",
      "  (0, 221)\t1\n",
      "  (0, 225)\t1\n",
      "  (0, 265)\t2\n",
      "  (0, 335)\t1\n",
      "  (0, 350)\t2\n",
      "  (0, 378)\t1\n",
      "  (0, 416)\t1\n",
      "  (0, 469)\t1\n",
      "  (0, 481)\t1\n",
      "  (0, 543)\t1\n",
      "  (0, 601)\t1\n",
      "  (0, 704)\t1\n",
      "  (0, 748)\t1\n",
      "  (0, 810)\t1\n",
      "  (0, 992)\t1\n",
      "  (0, 1109)\t1\n",
      "  (0, 1196)\t1\n",
      "  (0, 1221)\t1\n",
      "  (0, 1238)\t3\n",
      "  (0, 1313)\t1\n",
      "  (0, 1369)\t1\n",
      "  :\t:\n",
      "  (0, 2782)\t1\n",
      "  (0, 2805)\t1\n",
      "  (0, 2885)\t1\n",
      "  (0, 2886)\t1\n",
      "  (0, 2894)\t1\n",
      "  (0, 2903)\t1\n",
      "  (0, 3002)\t1\n",
      "  (0, 3003)\t5\n",
      "  (0, 3004)\t11\n",
      "  (0, 3010)\t1\n",
      "  (0, 3012)\t2\n",
      "  (0, 3029)\t1\n",
      "  (0, 3050)\t1\n",
      "  (0, 3052)\t6\n",
      "  (0, 3107)\t1\n",
      "  (0, 3122)\t1\n",
      "  (0, 3251)\t3\n",
      "  (0, 3263)\t1\n",
      "  (0, 3280)\t1\n",
      "  (0, 3295)\t1\n",
      "  (0, 3323)\t1\n",
      "  (0, 3328)\t4\n",
      "  (0, 3349)\t1\n",
      "  (0, 3364)\t1\n",
      "  (0, 3366)\t1\n"
     ]
    }
   ],
   "source": [
    "mystery_postcard = \"\"\"\n",
    "Henrik Ibsen, the hater of all social shams, was probably the first to realize this great truth. \n",
    "Nora leaves her husband, not—as the stupid critic would have it—because she is tired of her responsibilities or \n",
    "feels the need of woman's rights, but because she has come to know that for eight years she had lived with a \n",
    "stranger and borne him children. Can there be anything more humiliating, more degrading than a life-long \n",
    "proximity between two strangers? No need for the woman to know anything of the man, save his income. \n",
    "As to the knowledge of the woman—what is there to know except that she has a pleasing appearance? \n",
    "We have not yet outgrown the theologic myth that woman has no soul, that she is a mere appendix to man, \n",
    "made out of his rib just for the convenience of the gentleman who was so strong that he was afraid of his own shadow.\n",
    "\"\"\"\n",
    "# Define mystery_vector:\n",
    "mystery_vector = bow_vectorizer.transform([mystery_postcard])\n",
    "print(\"Mistery vector ->\", mystery_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc6963",
   "metadata": {},
   "source": [
    "## This Mystery Friend Gets Classified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ac51e",
   "metadata": {},
   "source": [
    "5. You've vectorized and prepared all the documents. Let's take a look at your friends' writing samples to get a sense of how they write.\n",
    "\n",
    "   Print out one document of each friend's writing - try any one between `0` and `140`. (Your friends' documents are stored in `goldman_docs`, `henson_docs`, and `wu_docs`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ca6fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a postcard from Goldman \n",
      "▼\n",
      " \n",
      "The history of human growth and development is at the same time the\n",
      "history of the terrible struggle of every new idea heralding the\n",
      "approach of a brighter dawn\n",
      "▲\n",
      "\n",
      "This is a postcard from Henson \n",
      "▼\n",
      " \n",
      "When the news of the discovery of the North Pole, by Commander Peary,\n",
      "was first sent to the world, a distinguished citizen of New York City,\n",
      "well versed in the affairs of the Peary Arctic Club, made the statement,\n",
      "that he was sure that Matt Henson had been with Commander Peary on the\n",
      "day of the discovery\n",
      "▲\n",
      "\n",
      "This is a postcard from Wu \n",
      "▼\n",
      " \n",
      "The Importance of Names\n",
      "\n",
      "  \"What's in a name?  That which we call a rose\n",
      "  By any other name would smell as sweet.\"\n",
      "\n",
      "\n",
      "Notwithstanding these lines, I maintain that the selection of names is\n",
      "important\n",
      "▲\n"
     ]
    }
   ],
   "source": [
    "# Print out a document from each friend:\n",
    "print(\"This is a postcard from Goldman \\n▼\\n\",goldman_docs[0])\n",
    "print(\"▲\")\n",
    "print(\"\\nThis is a postcard from Henson \\n▼\\n\",henson_docs[0])\n",
    "print(\"▲\")\n",
    "print(\"\\nThis is a postcard from Wu \\n▼\\n\", wu_docs[0])\n",
    "print(\"▲\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61585924",
   "metadata": {},
   "source": [
    "6. Have an inkling about which friend wrote the mystery card? We can use a classifier to confirm those suspicions...\n",
    "\n",
    "   Implement a Naive Bayes classifier using `MultinomialNB`. Save the result to `friends_classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d04847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define friends_classifier:\n",
    "friends_classifier =  MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c592f14",
   "metadata": {},
   "source": [
    "7. Train `friends_classifier` on `friends_vectors` and `friends_labels` using the classifier's `.fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab331e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_labels = [\"Emma\"] * 154 + [\"Matthew\"] * 141 + [\"Tingfang\"] * 166\n",
    "\n",
    "# Train the classifier:\n",
    "friends_classifier.fit(friends_vectors, friends_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40993688",
   "metadata": {},
   "source": [
    "8. Change `predictions` value from `[\"None Yet\"]` to the classifier's prediction about which friend wrote the postcard. You can do this by calling the classifier's `predict()` method on the `mystery_vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69dffb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change predictions:\n",
    "predictions = friends_classifier.predict(mystery_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93957d7",
   "metadata": {},
   "source": [
    "## Mystery Revealed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d3b26",
   "metadata": {},
   "source": [
    "9. Uncomment the final print statement and run the code block below to see who your mystery friend was all along!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "714701ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The postcard was from Emma!\n"
     ]
    }
   ],
   "source": [
    "mystery_friend = predictions[0] if predictions[0] else \"someone else\"\n",
    "\n",
    "# Uncomment the print statement:\n",
    "print(\"The postcard was from {}!\".format(mystery_friend))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d26a4b",
   "metadata": {},
   "source": [
    "10. But does it really work? Find some lines by Emma Goldman, Matthew Henson, and TingFang Wu on <a href=\"http://www.gutenberg.org\" target=\"_blank\">gutenberg.org</a> and save them to `mystery_postcard` to see how the classifier holds up!\n",
    "\n",
    "    Try using the `.predict_proba()` method instead of `.predict()` and print out `predictions` to see the estimated probabilities that the `mystery_postcard` was written by each person.\n",
    "   \n",
    "    What happens when you add in a recent email or text instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93572ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd91fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
